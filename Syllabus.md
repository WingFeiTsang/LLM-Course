# Syllabus

## Course Title
Big Data Mining and Deep Learning (Large Model Training: From Theory to Practice)

## Course Overview

This course provides an introduction to the advancement of deep learning techniques. From these semester (Spring 2025), we concentrate on LLM training and applications. Students will learn the theoretical foundations, practical techniques, and cutting-edge advancements in large model training. The course includes hands-on labs, case studies, and real-world applications.

## Course Outline

Module 1: Introduction to Large Language Models

Module 2: LLM Architecture and Training

Module 3: The application of LLMs

Module 4: Case Studies (AI Classroom, RAG, Course Agent)

## Hands-On Labs:

Lab 1: Training a small transformer model from scratch

Lab 2: Fine-tuning a pre-trained GPT model for text generation

Lab 3: Implementing distributed training using PyTorch

Lab 4: Optimizing memory usage with mixed precision training

Lab 5: Building a multimodal model for image captioning

## Assessment and Grading:

Class Participation (5%): Active engagement in discussions

Task 1 (5%): Use a local LLM (Qwen, LLaMa, or DeepSeek) with python. 

Task 2 (5%): Attack LLM to make it generate toxic repsonese. 

Task 3 (5%): Give an example to compare reponses with/without appropriate prompts.

Experiment 1 (40%): Train a small transformer model from scratch

Experiment 2 (40%): RAG, or AI Agent, Other tasks permitted by the mentor

# Recommended Textbooks and Resources

Please refer to the materials directory. 
